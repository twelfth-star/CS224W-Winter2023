现实中我们需要处理大规模的图，节点数在 10M 到 10B，边数在 100M 到 100B。

标准的随机梯度下降中取得样很多时候是分散的，因此导致 GNN 效果不好。

若采取 full-batch，则对于一次迭代 $H^{(k+1)}=\sigma(\tilde{A}H^{(k)}W_k^\text{T}+H^{(k)}B_k^\text{T})$，显存通常不够大（一般在 10GB 到 20GB），无法读入整张图。

# GraphSAGE Neighbour Sampling: Scaling up GNNs

方法一、随机训练
1. 随机取样 $M$ 个节点作为一个小批量
2. 对每个节点 $v$，获取其 $K$ 跳邻域，构建计算图，得到 $v$ 的 embedding
3. 计算 $M$ 个样本节点的损失函数平均值 $l_{\text{sub}}(\theta)$
4. SGD：$\theta\leftarrow\theta-\nabla l_{\text{sub}}(\theta)$

随机训练的缺点：
* 这些结点的 $K$ 跳邻域可能重合，造成计算的冗余。
* $K$ 很大时，或者领域中有个节点度数很大时，计算图都会很大。

解决办法：邻域取样技术。每一跳都只（随机）取样至多 $H$ 个相邻结点，则将会只有 $\prod_{k=1}^{K}H_k$ 个叶节点。

这里取 $H$ 个样本时，纯随机取样可能取到不重要的节点。使用带有重开的随机游走算法，选取重开分数 $R_i$ 最高的 $H$ 个样本。这一策略效果很好。

# Scaling up GNNs

随机训练的计算图容易重叠，此时的计算是冗余的。但在 full-batch 的 GNN 中，则每层只需要计算 $2\#(\text{edges})$ 的消息，相对高效，但我们无法把整个图全部读入 GPU。如何结合两者优点？取样一个紧凑的子图。